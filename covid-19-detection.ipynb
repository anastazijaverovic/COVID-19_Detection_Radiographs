{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem description\n\nFive times more deadly than the flu, COVID-19 causes significant morbidity and mortality. Like other pneumonias, pulmonary infection with COVID-19 results in inflammation and fluid in the lungs. COVID-19 looks very similar to other viral and bacterial pneumonias on chest radiographs, which makes it difficult to diagnose. This computer vision model for detection and localization of COVID-19 would help doctors provide a quick and confident diagnosis. As a result, patients could get the right treatment before the most severe effects of the virus take hold.\n\n\nCurrently, COVID-19 can be diagnosed via polymerase chain reaction to detect genetic material from the virus or chest radiograph. However, it can take a few hours and sometimes days before the molecular test results are back. By contrast, chest radiographs can be obtained in minutes. While guidelines exist to help radiologists differentiate COVID-19 from other types of infection, their assessments vary. In addition, non-radiologists could be supported with better localization of the disease, such as with a visual bounding box.\n\n\nIn this competition, the task is to identify and localize COVID-19 abnormalities on chest radiographs. In particular, categorization of the radiographs as negative for pneumonia or typical, indeterminate, or atypical for COVID-19.","metadata":{}},{"cell_type":"markdown","source":"* train_study_level.csv - the train study-level metadata, with one row for each study, including correct labels.\n* train_image_level.csv - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\n* sample_submission.csv - a sample submission file containing all image- and study-level IDs.\n* train folder - comprises 6334 chest scans in DICOM format, stored in paths with the form study/series/image\n* test folder - The hidden test dataset is of roughly the same scale as the training dataset. Studies in the test set may contain more than one label.","metadata":{}},{"cell_type":"markdown","source":"# Content table\n\n1. Importing the libraries\n2. Importing the datasets\n3. Data exploration\n4. Read Dicom files\n5. Feature engineering\n6. Credits","metadata":{}},{"cell_type":"markdown","source":"# Importing the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pydicom as dicom # Dicom (Digital Imaging in Medicine) - medical image datasets, storage and transfer\nimport os\nfrom tqdm import tqdm # allows you to output a smart progress bar by wrapping around any iterable\nimport glob # retrieve files/pathnames matching a specified pattern\nimport pprint # pretty-print” arbitrary Python data structures\nimport ast # ","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-28T18:33:00.282663Z","iopub.execute_input":"2021-05-28T18:33:00.283013Z","iopub.status.idle":"2021-05-28T18:33:01.403759Z","shell.execute_reply.started":"2021-05-28T18:33:00.282974Z","shell.execute_reply":"2021-05-28T18:33:01.402647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the datasets","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/siim-covid19-detection/'\ntrain_image_level = pd.read_csv(path + \"train_image_level.csv\")\ntrain_study_level = pd.read_csv(path + \"train_study_level.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.405397Z","iopub.execute_input":"2021-05-28T18:33:01.405848Z","iopub.status.idle":"2021-05-28T18:33:01.476213Z","shell.execute_reply.started":"2021-05-28T18:33:01.405801Z","shell.execute_reply":"2021-05-28T18:33:01.475273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data exploration","metadata":{}},{"cell_type":"markdown","source":"Let's have a look inside the train_image_level.","metadata":{}},{"cell_type":"code","source":"train_image_level.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.477887Z","iopub.execute_input":"2021-05-28T18:33:01.478163Z","iopub.status.idle":"2021-05-28T18:33:01.504774Z","shell.execute_reply.started":"2021-05-28T18:33:01.478135Z","shell.execute_reply":"2021-05-28T18:33:01.50369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_level.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.506221Z","iopub.execute_input":"2021-05-28T18:33:01.506505Z","iopub.status.idle":"2021-05-28T18:33:01.554723Z","shell.execute_reply.started":"2021-05-28T18:33:01.506478Z","shell.execute_reply":"2021-05-28T18:33:01.553762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 6334 unique values in the train_image_level dataframe.","metadata":{}},{"cell_type":"code","source":"train_study_level.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.555908Z","iopub.execute_input":"2021-05-28T18:33:01.556179Z","iopub.status.idle":"2021-05-28T18:33:01.566333Z","shell.execute_reply.started":"2021-05-28T18:33:01.55615Z","shell.execute_reply":"2021-05-28T18:33:01.565213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_study_level.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.567917Z","iopub.execute_input":"2021-05-28T18:33:01.568318Z","iopub.status.idle":"2021-05-28T18:33:01.59932Z","shell.execute_reply.started":"2021-05-28T18:33:01.568271Z","shell.execute_reply":"2021-05-28T18:33:01.598356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 6054 rows in the train_study_level dataframe. The number of unique values in study dataframe differs from the unique values in the images dataframe. Let's check how many studies have more than 1 image linked.","metadata":{}},{"cell_type":"code","source":"train_study_level_key = train_study_level.id.str[:-6]\ntraining_set = pd.merge(left = train_study_level, right = train_image_level, how = 'right', left_on = train_study_level_key, right_on = 'StudyInstanceUID')\ntraining_set.drop(['id_x'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.600263Z","iopub.execute_input":"2021-05-28T18:33:01.600728Z","iopub.status.idle":"2021-05-28T18:33:01.634947Z","shell.execute_reply.started":"2021-05-28T18:33:01.600697Z","shell.execute_reply":"2021-05-28T18:33:01.633785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at these studies with multiple images:","metadata":{}},{"cell_type":"code","source":"training_set[training_set.groupby('StudyInstanceUID')['id_y'].transform('size') > 1].sort_values('StudyInstanceUID')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.638675Z","iopub.execute_input":"2021-05-28T18:33:01.63898Z","iopub.status.idle":"2021-05-28T18:33:01.668392Z","shell.execute_reply.started":"2021-05-28T18:33:01.638953Z","shell.execute_reply":"2021-05-28T18:33:01.667217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Dicom files","metadata":{}},{"cell_type":"markdown","source":"Function used to locate image from the path:","metadata":{}},{"cell_type":"code","source":"def extract_image(i):\n    path_train = path + 'train/' + training_set.loc[i, 'StudyInstanceUID']\n    last_folder_in_path = os.listdir(path_train)[0]\n    path_train = path_train + '/{}/'.format(last_folder_in_path)\n    img_id = training_set.loc[i, 'id_y'].replace('_image','.dcm')\n    print(img_id)\n    data_file = dicom.dcmread(path_train + img_id)\n    img = data_file.pixel_array\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.670316Z","iopub.execute_input":"2021-05-28T18:33:01.670739Z","iopub.status.idle":"2021-05-28T18:33:01.676957Z","shell.execute_reply.started":"2021-05-28T18:33:01.670692Z","shell.execute_reply":"2021-05-28T18:33:01.675774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Images and rectangles visualization","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\n\nfor row in range(9):\n    img = extract_image(row)\n    if (training_set.loc[row,'boxes'] == training_set.loc[row,'boxes']):\n        boxes = ast.literal_eval(training_set.loc[row,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(training_set.loc[row, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:01.678285Z","iopub.execute_input":"2021-05-28T18:33:01.678616Z","iopub.status.idle":"2021-05-28T18:33:13.614873Z","shell.execute_reply.started":"2021-05-28T18:33:01.678575Z","shell.execute_reply":"2021-05-28T18:33:13.610713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"markdown","source":"Count the number of opacities in the image","metadata":{}},{"cell_type":"code","source":"Opacity_Count = training_set['label'].str.count('opacity')\ntraining_set['Opacity_Count'] = Opacity_Count.values","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.616063Z","iopub.execute_input":"2021-05-28T18:33:13.616518Z","iopub.status.idle":"2021-05-28T18:33:13.626137Z","shell.execute_reply.started":"2021-05-28T18:33:13.61647Z","shell.execute_reply":"2021-05-28T18:33:13.625354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sum of areas of rectangles - assumption : the bigger the rectangle - the bigger the opacity","metadata":{}},{"cell_type":"code","source":"image_rectangles_areas = []\n\nfor row in range(6334):#len(training_set.index)):\n    image_rectangles_area_sum = 0\n    rectangle_area = 0\n    if (training_set.loc[row,'boxes'] == training_set.loc[row,'boxes']):\n        boxes = ast.literal_eval(training_set.loc[row,'boxes'])\n        for box in boxes:\n            rectangle_area = box['width'] * box['height']\n            #print('Rectangle area : {} '.format(rectangle_area))\n            image_rectangles_area_sum = image_rectangles_area_sum + rectangle_area\n            #training_set['Image_Rectangles_Area_Sum'] = \n        image_rectangles_areas.append(image_rectangles_area_sum)\n    else:\n        image_rectangles_area_sum = image_rectangles_area_sum + rectangle_area\n        image_rectangles_areas.append(image_rectangles_area_sum)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.627262Z","iopub.execute_input":"2021-05-28T18:33:13.627712Z","iopub.status.idle":"2021-05-28T18:33:13.912786Z","shell.execute_reply.started":"2021-05-28T18:33:13.627666Z","shell.execute_reply":"2021-05-28T18:33:13.911976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set['Rectangle_Area'] = image_rectangles_areas","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.914016Z","iopub.execute_input":"2021-05-28T18:33:13.914589Z","iopub.status.idle":"2021-05-28T18:33:13.921809Z","shell.execute_reply.started":"2021-05-28T18:33:13.914529Z","shell.execute_reply":"2021-05-28T18:33:13.920834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating buckets - rectangle areas","metadata":{}},{"cell_type":"markdown","source":"First see the distribution of the rectangle areas","metadata":{}},{"cell_type":"code","source":"training_set['Rectangle_Area'] = round(training_set['Rectangle_Area'],2)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.923215Z","iopub.execute_input":"2021-05-28T18:33:13.923608Z","iopub.status.idle":"2021-05-28T18:33:13.935394Z","shell.execute_reply.started":"2021-05-28T18:33:13.923565Z","shell.execute_reply":"2021-05-28T18:33:13.934442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set['Rectangle_Area']","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.936848Z","iopub.execute_input":"2021-05-28T18:33:13.937267Z","iopub.status.idle":"2021-05-28T18:33:13.951152Z","shell.execute_reply.started":"2021-05-28T18:33:13.937223Z","shell.execute_reply":"2021-05-28T18:33:13.950019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.qcut(training_set['Rectangle_Area'], q = 4)\n\n#training_set.boxplot(by = \"Negative for Pneumonia\",column = ['Rectangle_Area'],grid = True, layout=(1, 1))\n\ncut_labels_4 = ['0', '<1e6', '<2e6', '<4e6', '<8e6']\ncut_bins = [-1, 0, 1000000, 2000000, 4000000, 8000000]\ntraining_set['Rectangle_Area_Bin'] = pd.cut(training_set['Rectangle_Area'], bins=cut_bins, labels=cut_labels_4)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.952279Z","iopub.execute_input":"2021-05-28T18:33:13.952653Z","iopub.status.idle":"2021-05-28T18:33:13.964395Z","shell.execute_reply.started":"2021-05-28T18:33:13.95262Z","shell.execute_reply":"2021-05-28T18:33:13.963607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n\nplt.figure(figsize = (16, 14))\nsn.set(font_scale = 1.2)\nsn.set_style('ticks')\n\nfor i, column in enumerate(columns):\n    plt.subplot(3, 3, i + 1)\n    sn.countplot(data = training_set, x = 'Rectangle_Area_Bin', hue = column, palette = ['#d02f52',\"#55a0ee\"])\n    \nsn.despine()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:33:13.965365Z","iopub.execute_input":"2021-05-28T18:33:13.965786Z","iopub.status.idle":"2021-05-28T18:33:14.529717Z","shell.execute_reply.started":"2021-05-28T18:33:13.965751Z","shell.execute_reply":"2021-05-28T18:33:14.528662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#columns = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nopacity = sorted(list(training_set['Rectangle_Area_Bin'].value_counts().index))\n\nfor i in opacity:\n    Count_Series = training_set[training_set['Rectangle_Area_Bin'] == i].iloc[:,[1, 2, 3, 4]].sum()\n    fig = plt.figure(figsize=(12,3))\n    sn.barplot(x = Count_Series.index, y = Count_Series.values/sum(training_set['Rectangle_Area_Bin'] == i))\n    plt.title('Rectangle_Area_Bin : {} '.format(i))\n    plt.plot()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:46:52.167534Z","iopub.execute_input":"2021-05-28T18:46:52.168045Z","iopub.status.idle":"2021-05-28T18:46:52.812676Z","shell.execute_reply.started":"2021-05-28T18:46:52.167993Z","shell.execute_reply":"2021-05-28T18:46:52.811646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rectangle area and opacity count","metadata":{}},{"cell_type":"code","source":"#columns = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nopacity = sorted(list(training_set['Opacity_Count'].value_counts().index))\n\nfor i in opacity:\n    Count_Series = training_set[training_set['Opacity_Count'] == i].iloc[:,[1, 2, 3, 4]].sum()\n    fig = plt.figure(figsize=(12,3))\n    sn.barplot(x = Count_Series.index, y = Count_Series.values/sum(training_set['Opacity_Count'] == i))\n    plt.title('OpacityCount : {} '.format(i))\n    plt.plot()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T18:45:29.130518Z","iopub.execute_input":"2021-05-28T18:45:29.130928Z","iopub.status.idle":"2021-05-28T18:45:30.236167Z","shell.execute_reply.started":"2021-05-28T18:45:29.130891Z","shell.execute_reply":"2021-05-28T18:45:30.235059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Position of the rectangle by quadrants (4 bins - 4 quadrants)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image metadata","metadata":{}},{"cell_type":"code","source":"training_paths = []\n\nfor sid in tqdm(training_set['StudyInstanceUID']):\n    training_paths.append(glob.glob(os.path.join(train_directory, sid +\"/*/*\"))[0])\n\ntraining_set['path'] = training_paths","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voi_lut=True\nfix_monochrome=True\n\ndef dicom_dataset_to_dict(filename,func):\n    \"\"\"Credit: https://github.com/pydicom/pydicom/issues/319\n               https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    \"\"\"\n    \n    dicom_header = dicom.dcmread(filename) \n    \n    #====== DICOM FILE DATA ======\n    dicom_dict = {}\n    repr(dicom_header)\n    for dicom_value in dicom_header.values():\n        if dicom_value.tag == (0x7fe0, 0x0010):\n            #discard pixel data\n            continue\n        if type(dicom_value.value) == dicom.dataset.Dataset:\n            dicom_dict[dicom_value.name] = dicom_dataset_to_dict(dicom_value.value)\n        else:\n            v = _convert_value(dicom_value.value)\n            dicom_dict[dicom_value.name] = v\n      \n    del dicom_dict['Pixel Representation']\n    \n    if func!='metadata_df':\n        #====== DICOM IMAGE DATA ======\n        # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n        if voi_lut:\n            data = apply_voi_lut(dicom_header.pixel_array, dicom_header)\n        else:\n            data = dicom_header.pixel_array\n        # depending on this value, X-ray may look inverted - fix that:\n        if fix_monochrome and dicom_header.PhotometricInterpretation == \"MONOCHROME1\":\n            data = np.amax(data) - data\n        data = data - np.min(data)\n        data = data / np.max(data)\n        modified_image_data = (data * 255).astype(np.uint8)\n    \n        return dicom_dict, modified_image_data\n    \n    else:\n        return dicom_dict\n\ndef _sanitise_unicode(s):\n    return s.replace(u\"\\u0000\", \"\").strip()\n\ndef _convert_value(v):\n    t = type(v)\n    if t in (list, int, float):\n        cv = v\n    elif t == str:\n        cv = _sanitise_unicode(v)\n    elif t == bytes:\n        s = v.decode('ascii', 'replace')\n        cv = _sanitise_unicode(s)\n    elif t == dicom.valuerep.DSfloat:\n        cv = float(v)\n    elif t == dicom.valuerep.IS:\n        cv = int(v)\n    else:\n        cv = repr(v)\n    return cv\n\nfor filename in train_df.path[0:5]:\n    df, img_array = dicom_dataset_to_dict(filename, 'fetch_both_values')\n    \n    pprint.pprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T19:08:50.561724Z","iopub.execute_input":"2021-05-28T19:08:50.562102Z","iopub.status.idle":"2021-05-28T19:08:50.570194Z","shell.execute_reply.started":"2021-05-28T19:08:50.562071Z","shell.execute_reply":"2021-05-28T19:08:50.569093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Outliers and irregularities in the data","metadata":{}},{"cell_type":"markdown","source":"# Credits\n\n* https://github.com/pydicom/pydicom/issues/319\n* https://www.kaggle.com/songseungwon/siim-covid-19-detection-10-step-tutorial-1","metadata":{}}]}