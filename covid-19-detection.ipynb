{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem description\n\nFive times more deadly than the flu, COVID-19 causes significant morbidity and mortality. Like other pneumonias, pulmonary infection with COVID-19 results in inflammation and fluid in the lungs. COVID-19 looks very similar to other viral and bacterial pneumonias on chest radiographs, which makes it difficult to diagnose. This computer vision model for detection and localization of COVID-19 would help doctors provide a quick and confident diagnosis. As a result, patients could get the right treatment before the most severe effects of the virus take hold.\n\n\nCurrently, COVID-19 can be diagnosed via polymerase chain reaction to detect genetic material from the virus or chest radiograph. However, it can take a few hours and sometimes days before the molecular test results are back. By contrast, chest radiographs can be obtained in minutes. While guidelines exist to help radiologists differentiate COVID-19 from other types of infection, their assessments vary. In addition, non-radiologists could be supported with better localization of the disease, such as with a visual bounding box.\n\n\nIn this competition, the task is to identify and localize COVID-19 abnormalities on chest radiographs. In particular, categorization of the radiographs as negative for pneumonia or typical, indeterminate, or atypical for COVID-19.","metadata":{}},{"cell_type":"markdown","source":"**Categorization of the radiographs:**\n\n* NEGATIVE FOR PNEUMONIA - No lung opacities\n\n* TYPICAL APPEARANCE - Multifocal bilateral, peripheral opacities with rounded morphology, lower lung–predominant distribution\n\n* INDETERMINATE APPEARANCE - Absence of typical findings AND unilateral, central or upper lung predominant distribution\n\n* ATYPICAL APPEARANCE - Pneumothorax, pleural effusion, pulmonary edema, lobar consolidation, solitary lung nodule or mass, diffuse tiny nodules, cavity","metadata":{}},{"cell_type":"markdown","source":"**Input data:**\n\n* train_study_level.csv - the train study-level metadata, with one row for each study, including correct labels.\n* train_image_level.csv - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\n* sample_submission.csv - a sample submission file containing all image- and study-level IDs.\n* train folder - comprises 6334 chest scans in DICOM format, stored in paths with the form study/series/image\n* test folder - The hidden test dataset is of roughly the same scale as the training dataset. Studies in the test set may contain more than one label.","metadata":{}},{"cell_type":"markdown","source":"# Content table\n\n1. Importing the libraries\n2. Importing the datasets\n3. Data exploration\n4. Read Dicom files\n5. Feature engineering\n6. References","metadata":{}},{"cell_type":"markdown","source":"# Importing the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pydicom as dicom # Dicom (Digital Imaging in Medicine) - medical image datasets, storage and transfer\nimport os\nfrom tqdm import tqdm # allows you to output a smart progress bar by wrapping around any iterable\nimport glob # retrieve files/pathnames matching a specified pattern\nimport pprint # pretty-print” arbitrary Python data structures\nimport ast # \nfrom pydicom.pixel_data_handlers.util import apply_voi_lut #\nimport wandb #","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T15:24:58.077314Z","iopub.execute_input":"2021-06-04T15:24:58.077734Z","iopub.status.idle":"2021-06-04T15:24:59.896851Z","shell.execute_reply.started":"2021-06-04T15:24:58.077696Z","shell.execute_reply":"2021-06-04T15:24:59.895284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the datasets","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/siim-covid19-detection/'\ntrain_image_level = pd.read_csv(path + \"train_image_level.csv\")\ntrain_study_level = pd.read_csv(path + \"train_study_level.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:24:59.899409Z","iopub.execute_input":"2021-06-04T15:24:59.89981Z","iopub.status.idle":"2021-06-04T15:24:59.979822Z","shell.execute_reply.started":"2021-06-04T15:24:59.899769Z","shell.execute_reply":"2021-06-04T15:24:59.978168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data exploration","metadata":{}},{"cell_type":"markdown","source":"Let's have a look inside the train_image_level.","metadata":{}},{"cell_type":"code","source":"train_image_level.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:24:59.982585Z","iopub.execute_input":"2021-06-04T15:24:59.983086Z","iopub.status.idle":"2021-06-04T15:25:00.198736Z","shell.execute_reply.started":"2021-06-04T15:24:59.983033Z","shell.execute_reply":"2021-06-04T15:25:00.197287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_level.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.200753Z","iopub.execute_input":"2021-06-04T15:25:00.20109Z","iopub.status.idle":"2021-06-04T15:25:00.265223Z","shell.execute_reply.started":"2021-06-04T15:25:00.201059Z","shell.execute_reply":"2021-06-04T15:25:00.264038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 6334 unique values in the train_image_level dataframe.","metadata":{}},{"cell_type":"code","source":"train_study_level.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.266492Z","iopub.execute_input":"2021-06-04T15:25:00.266963Z","iopub.status.idle":"2021-06-04T15:25:00.277718Z","shell.execute_reply.started":"2021-06-04T15:25:00.266915Z","shell.execute_reply":"2021-06-04T15:25:00.276876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_study_level.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.278921Z","iopub.execute_input":"2021-06-04T15:25:00.279466Z","iopub.status.idle":"2021-06-04T15:25:00.318048Z","shell.execute_reply.started":"2021-06-04T15:25:00.279423Z","shell.execute_reply":"2021-06-04T15:25:00.31707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 6054 rows in the train_study_level dataframe. The number of unique values in study dataframe differs from the unique values in the images dataframe. Let's check how many studies have more than 1 image linked.","metadata":{}},{"cell_type":"code","source":"train_study_level_key = train_study_level.id.str[:-6]\ntraining_set = pd.merge(left = train_study_level, right = train_image_level, how = 'right', left_on = train_study_level_key, right_on = 'StudyInstanceUID')\ntraining_set.drop(['id_x'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.319703Z","iopub.execute_input":"2021-06-04T15:25:00.320051Z","iopub.status.idle":"2021-06-04T15:25:00.368775Z","shell.execute_reply.started":"2021-06-04T15:25:00.320015Z","shell.execute_reply":"2021-06-04T15:25:00.367857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at these studies with multiple images:","metadata":{}},{"cell_type":"code","source":"training_set[training_set.groupby('StudyInstanceUID')['id_y'].transform('size') > 1].sort_values('StudyInstanceUID')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.371599Z","iopub.execute_input":"2021-06-04T15:25:00.371944Z","iopub.status.idle":"2021-06-04T15:25:00.408521Z","shell.execute_reply.started":"2021-06-04T15:25:00.37191Z","shell.execute_reply":"2021-06-04T15:25:00.40738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Dicom files","metadata":{}},{"cell_type":"markdown","source":"Function used to locate image from the path:","metadata":{}},{"cell_type":"code","source":"def extract_image(i):\n    path_train = path + 'train/' + training_set.loc[i, 'StudyInstanceUID']\n    last_folder_in_path = os.listdir(path_train)[0]\n    path_train = path_train + '/{}/'.format(last_folder_in_path)\n    img_id = training_set.loc[i, 'id_y'].replace('_image','.dcm')\n    print(img_id)\n    data_file = dicom.dcmread(path_train + img_id)\n    img = data_file.pixel_array\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.410729Z","iopub.execute_input":"2021-06-04T15:25:00.411068Z","iopub.status.idle":"2021-06-04T15:25:00.416854Z","shell.execute_reply.started":"2021-06-04T15:25:00.411038Z","shell.execute_reply":"2021-06-04T15:25:00.415895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Images and rectangles visualization","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\n\nfor row in range(9):\n    img = extract_image(row)\n    if (training_set.loc[row,'boxes'] == training_set.loc[row,'boxes']):\n        boxes = ast.literal_eval(training_set.loc[row,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec = 'r', fc = 'none', lw = 2.\n                                            )\n            axes[row].add_patch(p)\n    axes[row].imshow(img, cmap = 'gray')\n    axes[row].set_title(training_set.loc[row, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:00.418147Z","iopub.execute_input":"2021-06-04T15:25:00.418562Z","iopub.status.idle":"2021-06-04T15:25:13.552746Z","shell.execute_reply.started":"2021-06-04T15:25:00.41853Z","shell.execute_reply":"2021-06-04T15:25:13.551647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"markdown","source":"**Opacity_Count** - Count the number of opacities in the image","metadata":{}},{"cell_type":"code","source":"Opacity_Count = training_set['label'].str.count('opacity')\ntraining_set['Opacity_Count'] = Opacity_Count.values","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:13.554654Z","iopub.execute_input":"2021-06-04T15:25:13.555512Z","iopub.status.idle":"2021-06-04T15:25:13.571302Z","shell.execute_reply.started":"2021-06-04T15:25:13.555461Z","shell.execute_reply":"2021-06-04T15:25:13.56952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Rectange_Area** - Sum of areas of rectangles - assumption : the bigger the rectangle - the bigger the opacity","metadata":{}},{"cell_type":"code","source":"image_rectangles_areas = []\n\nfor row in range(6334):#len(training_set.index)):\n    image_rectangles_area_sum = 0\n    rectangle_area = 0\n    if (training_set.loc[row,'boxes'] == training_set.loc[row,'boxes']):\n        boxes = ast.literal_eval(training_set.loc[row,'boxes'])\n        for box in boxes:\n            rectangle_area = box['width'] * box['height']\n            image_rectangles_area_sum = image_rectangles_area_sum + rectangle_area\n        image_rectangles_areas.append(image_rectangles_area_sum)\n    else:\n        image_rectangles_area_sum = image_rectangles_area_sum + rectangle_area\n        image_rectangles_areas.append(image_rectangles_area_sum)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:13.57347Z","iopub.execute_input":"2021-06-04T15:25:13.573908Z","iopub.status.idle":"2021-06-04T15:25:13.986688Z","shell.execute_reply.started":"2021-06-04T15:25:13.573867Z","shell.execute_reply":"2021-06-04T15:25:13.985637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set['Rectangle_Area'] = image_rectangles_areas","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:13.987886Z","iopub.execute_input":"2021-06-04T15:25:13.988204Z","iopub.status.idle":"2021-06-04T15:25:13.995353Z","shell.execute_reply.started":"2021-06-04T15:25:13.988162Z","shell.execute_reply":"2021-06-04T15:25:13.993921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating buckets - rectangle areas","metadata":{}},{"cell_type":"markdown","source":"First see the distribution of the rectangle areas","metadata":{}},{"cell_type":"code","source":"training_set['Rectangle_Area'] = round(training_set['Rectangle_Area'],2)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:13.996955Z","iopub.execute_input":"2021-06-04T15:25:13.997432Z","iopub.status.idle":"2021-06-04T15:25:14.00958Z","shell.execute_reply.started":"2021-06-04T15:25:13.997387Z","shell.execute_reply":"2021-06-04T15:25:14.008747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set['Rectangle_Area']","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:14.011184Z","iopub.execute_input":"2021-06-04T15:25:14.011899Z","iopub.status.idle":"2021-06-04T15:25:14.028716Z","shell.execute_reply.started":"2021-06-04T15:25:14.011865Z","shell.execute_reply":"2021-06-04T15:25:14.027594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.qcut(training_set['Rectangle_Area'], q = 4)\n\n#training_set.boxplot(by = \"Negative for Pneumonia\",column = ['Rectangle_Area'],grid = True, layout=(1, 1))\n\ncut_labels_4 = ['0', '<1e6', '<2e6', '<4e6', '<8e6']\ncut_bins = [-1, 0, 1000000, 2000000, 4000000, 8000000]\ntraining_set['Rectangle_Area_Bin'] = pd.cut(training_set['Rectangle_Area'], bins=cut_bins, labels=cut_labels_4)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:14.030554Z","iopub.execute_input":"2021-06-04T15:25:14.030907Z","iopub.status.idle":"2021-06-04T15:25:14.047263Z","shell.execute_reply.started":"2021-06-04T15:25:14.030877Z","shell.execute_reply":"2021-06-04T15:25:14.04629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n\nplt.figure(figsize = (16, 14))\nsn.set(font_scale = 1.2)\nsn.set_style('ticks')\n\nfor i, column in enumerate(columns):\n    plt.subplot(3, 3, i + 1)\n    sn.countplot(data = training_set, x = 'Rectangle_Area_Bin', hue = column, palette = ['#d02f52',\"#55a0ee\"])\n    \nsn.despine()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:14.048727Z","iopub.execute_input":"2021-06-04T15:25:14.049298Z","iopub.status.idle":"2021-06-04T15:25:14.814879Z","shell.execute_reply.started":"2021-06-04T15:25:14.049262Z","shell.execute_reply":"2021-06-04T15:25:14.813605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#columns = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nopacity = sorted(list(training_set['Rectangle_Area_Bin'].value_counts().index))\n\nfor i in opacity:\n    Count_Series = training_set[training_set['Rectangle_Area_Bin'] == i].iloc[:,[1, 2, 3, 4]].sum()\n    fig = plt.figure(figsize=(12,3))\n    sn.barplot(x = Count_Series.index, y = Count_Series.values/sum(training_set['Rectangle_Area_Bin'] == i))\n    plt.title('Rectangle_Area_Bin : {} '.format(i))\n    plt.plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:14.81709Z","iopub.execute_input":"2021-06-04T15:25:14.817556Z","iopub.status.idle":"2021-06-04T15:25:15.583495Z","shell.execute_reply.started":"2021-06-04T15:25:14.81751Z","shell.execute_reply":"2021-06-04T15:25:15.582718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rectangle area and opacity count","metadata":{}},{"cell_type":"code","source":"#columns = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nopacity = sorted(list(training_set['Opacity_Count'].value_counts().index))\n\nfor i in opacity:\n    Count_Series = training_set[training_set['Opacity_Count'] == i].iloc[:,[1, 2, 3, 4]].sum()\n    fig = plt.figure(figsize=(12,3))\n    sn.barplot(x = Count_Series.index, y = Count_Series.values/sum(training_set['Opacity_Count'] == i))\n    plt.title('OpacityCount : {} '.format(i))\n    plt.plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:15.584706Z","iopub.execute_input":"2021-06-04T15:25:15.58516Z","iopub.status.idle":"2021-06-04T15:25:16.85217Z","shell.execute_reply.started":"2021-06-04T15:25:15.585126Z","shell.execute_reply":"2021-06-04T15:25:16.851423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TBD**: Position of the rectangle by quadrants (4 bins - 4 quadrants)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Image metadata**","metadata":{}},{"cell_type":"code","source":"training_paths = []\ntrain_directory = \"../input/siim-covid19-detection/train/\"\n\nfor sid in tqdm(training_set['StudyInstanceUID']):\n    training_paths.append(glob.glob(os.path.join(train_directory, sid +\"/*/*\"))[0])\n\ntraining_set['path'] = training_paths","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:16.853385Z","iopub.execute_input":"2021-06-04T15:25:16.853776Z","iopub.status.idle":"2021-06-04T15:25:38.689352Z","shell.execute_reply.started":"2021-06-04T15:25:16.853745Z","shell.execute_reply":"2021-06-04T15:25:38.688327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voi_lut=True\nfix_monochrome=True\n\ndef dicom_dataset_to_dict(filename,func):\n    \"\"\"Credit: https://github.com/pydicom/pydicom/issues/319\n               https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    \"\"\"\n    \n    dicom_header = dicom.dcmread(filename) \n    \n    #====== DICOM FILE DATA ======\n    dicom_dict = {}\n    repr(dicom_header)\n    for dicom_value in dicom_header.values():\n        if dicom_value.tag == (0x7fe0, 0x0010):\n            #discard pixel data\n            continue\n        if type(dicom_value.value) == dicom.dataset.Dataset:\n            dicom_dict[dicom_value.name] = dicom_dataset_to_dict(dicom_value.value)\n        else:\n            v = _convert_value(dicom_value.value)\n            dicom_dict[dicom_value.name] = v\n      \n    del dicom_dict['Pixel Representation']\n    \n    if func != 'metadata_df':\n        #====== DICOM IMAGE DATA ======\n        # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n        if voi_lut:\n            data = apply_voi_lut(dicom_header.pixel_array, dicom_header)\n        else:\n            data = dicom_header.pixel_array\n        # depending on this value, X-ray may look inverted - fix that:\n        if fix_monochrome and dicom_header.PhotometricInterpretation == \"MONOCHROME1\":\n            data = np.amax(data) - data\n        data = data - np.min(data)\n        data = data / np.max(data)\n        modified_image_data = (data * 255).astype(np.uint8)\n    \n        return dicom_dict, modified_image_data\n    \n    else:\n        return dicom_dict\n\ndef _sanitise_unicode(s):\n    return s.replace(u\"\\u0000\", \"\").strip()\n\ndef _convert_value(v):\n    t = type(v)\n    if t in (list, int, float):\n        cv = v\n    elif t == str:\n        cv = _sanitise_unicode(v)\n    elif t == bytes:\n        s = v.decode('ascii', 'replace')\n        cv = _sanitise_unicode(s)\n    elif t == dicom.valuerep.DSfloat:\n        cv = float(v)\n    elif t == dicom.valuerep.IS:\n        cv = int(v)\n    else:\n        cv = repr(v)\n    return cv\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:38.691482Z","iopub.execute_input":"2021-06-04T15:25:38.692154Z","iopub.status.idle":"2021-06-04T15:25:38.705935Z","shell.execute_reply.started":"2021-06-04T15:25:38.692088Z","shell.execute_reply":"2021-06-04T15:25:38.704894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting the dictionary data to the dataframe and dropping the columns not needed","metadata":{}},{"cell_type":"code","source":"metadata = []\n\nfor filename in training_set.path:\n    try:\n        data_di = dicom_dataset_to_dict(filename,'metadata_df')\n        metadata.append(data_di)\n    except:\n        continue\n\ndicom_data_df = pd.DataFrame(metadata)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:25:38.707421Z","iopub.execute_input":"2021-06-04T15:25:38.707761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 5000)\ndicom_data_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dicom_data_df.drop(['Specific Character Set', 'SOP Class UID','SOP Instance UID','Study Date','Study Time','Accession Number','Patient ID'.'Accession Number'.'Rows','Columns'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TBD**: Get the metadata information as new columns in an existing dataframe","metadata":{}},{"cell_type":"markdown","source":"**TBD**: Outliers and irregularities in the data","metadata":{}},{"cell_type":"markdown","source":"# References\n\n* https://github.com/pydicom/pydicom/issues/319\n* https://www.kaggle.com/songseungwon/siim-covid-19-detection-10-step-tutorial-1\n* https://www.kaggle.com/ruchi798/siim-covid-19-detection-eda-data-augmentation#DICOM-data","metadata":{}}]}